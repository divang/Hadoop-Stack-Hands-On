mysql> create database testDb; 
mysql> use testDb;
mysql> create table student(id integer,name char(20));
mysql> insert into student values(1,'Stefin');
mysql> insert into student values(2,'Aaditya');

sqoopÂ import --connect jdbc:mysql://localhost/testDb --username root --table student --m 1


Store to specific Hadoop directory:
sqoop import \
--connect jdbc:mysql://localhost/testDb \
--username root \
--table student \
--m 1 \
--where "name='Aaditya'" \
--target-dir /student_from_mysql

Incremental import:
mysql> insert into student values(4,'Sudhanshu');
mysql> insert into student values(5,'Nitya');

sqoop import \
--connect jdbc:mysql://localhost/testDb \
--username root \
--table student \
--m 1 \
--incremental append \
--check-column id \
--last-value 3

Export:

mysql> CREATE TABLE employee ( 
   id INT NOT NULL PRIMARY KEY, 
   name VARCHAR(20), 
   deg VARCHAR(20),
   salary INT,
   dept VARCHAR(10));

Create a file in HDFS:
emp_data.txt
1201, gopal,     manager, 50000, TP
1202, manisha,   preader, 50000, TP
1203, kalil,     php dev, 30000, AC
1204, prasanth,  php dev, 30000, AC
1205, kranthi,   admin,   20000, TP
1206, satish p,  grp des, 20000, GR

sqoop export \
--connect jdbc:mysql://localhost/db \
--username root \
--table employee \ 
--export-dir emp_data.txt

Sqoop Job:
sqoop job --create myjob \
--import \
--connect jdbc:mysql://localhost/db \
--username root \
--table employee --m 1

sqoop job --list
sqoop job --show myjob
sqoop job --exec myjob

